{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UkouS8Y-o3R9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "70-XsHkDGUKu"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Checking if a GPU is available for training a model\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gZkz29ilGWd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat: /proc/meminfo: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Display detailed information about the system's memory\n",
        "!cat /proc/meminfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6UbfwSrGZsH"
      },
      "outputs": [],
      "source": [
        "# Display detailed information about the system's central processing unit (CPU)\n",
        "!cat /proc/cpuinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BREirreEUnGg"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "    f.write('{\"username\":\"khushalidaga08\",\"key\":\"c7aaa2a8acee7e33b56fe4195f198b4d\"}')\n",
        "    # Put your kaggle username & key here\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smnVE5DpUoxh"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download behrad3d/nasa-cmaps\n",
        "! mkdir train\n",
        "! unzip nasa-cmaps.zip -d train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzoL9ofEgJJf"
      },
      "outputs": [],
      "source": [
        "PM_train = '/content/train/CMaps/train_FD001.txt'\n",
        "PM_test = '/content/train/CMaps/test_FD001.txt'\n",
        "PM_truth = '/content/train/CMaps/RUL_FD001.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BsYPkY7gYGx"
      },
      "source": [
        "# Binary classification\n",
        "Predict if an asset will fail within certain time frame (e.g. cycles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfpzPSgG-If3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Setting seed for reproducibility\n",
        "np.random.seed(1234)\n",
        "PYTHONHASHSEED = 0\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from torchinfo import summaryimport keras\n",
        "\n",
        "# define path to save model\n",
        "model_path = 'binary_model.keras'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EilFg--x-ety"
      },
      "source": [
        "## Data Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjbfnUZGgc3C"
      },
      "outputs": [],
      "source": [
        "# Read training data - Aircraft engine run-to-failure data\n",
        "train_df = NotImplemented # Read the txt file, use appropriate separator and header\n",
        "train_df.drop(NotImplemented, axis=1, inplace=True)  # Explore the data on your own and remove unnecessary columns\n",
        "train_df.columns = [NotImplemented]  # Assign names to all the columns\n",
        "\n",
        "train_df = train_df.sort_values([NotImplemented, NotImplemented])  # Sort by id and cycle\n",
        "\n",
        "# Read test data - Aircraft engine operating data without failure events recorded\n",
        "test_df = NotImplemented  # Read the txt file, use appropriate separator and header\n",
        "test_df.drop(NotImplemented, axis=1, inplace=True)  # Explore the data on your own and remove unnecessary columns\n",
        "test_df.columns = [NotImplemented]  # Assign names to all the columns\n",
        "\n",
        "# Read ground truth data - True remaining cycles for each engine in testing data\n",
        "truth_df = NotImplemented # Read the txt file, use appropriate separator and header\n",
        "truth_df.drop(NotImplemented, axis=1, inplace=True)  # Explore the data on your own and remove unnecessary columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEpD7amS-lpu"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulY14O06knOI"
      },
      "outputs": [],
      "source": [
        "#######\n",
        "# TRAIN\n",
        "#######\n",
        "# Data Labeling - generate column RUL (Remaining Useful Life or Time to Failure)\n",
        "\n",
        "# TODO: Calculate the maximum cycle value for each engine (id) and store it in a new DataFrame (rul)\n",
        "rul = NotImplemented\n",
        "# TODO: Rename the columns in the rul DataFrame\n",
        "rul.columns = NotImplemented\n",
        "# TODO: Merge the rul DataFrame with the original train_df based on the 'id' column\n",
        "train_df = NotImplemented\n",
        "# TODO: Calculate the Remaining Useful Life (RUL) by subtracting the current cycle from the maximum cycle\n",
        "train_df['RUL'] = NotImplemented\n",
        "# TODO: Remove the temporary column used to calculate RUL\n",
        "train_df.drop(NotImplemented, axis=1, inplace=True)\n",
        "\n",
        "# Generate label columns for training data\n",
        "# We will only make use of \"label1\" for binary classification,\n",
        "# while trying to answer the question: is a specific engine going to fail within w1 cycles?\n",
        "w1 = 30\n",
        "w0 = 15\n",
        "\n",
        "# TODO: Create a binary label ('label1') indicating if the engine will fail within w1 cycles (1) or not (0)\n",
        "train_df['label1'] = NotImplemented  # Replace with the correct threshold value and label values\n",
        "# TODO: Initialize a second label ('label2') as a copy of 'label1'\n",
        "train_df['label2'] = NotImplemented\n",
        "# TODO: Update 'label2' to indicate if the engine will fail within w0 cycles (2) or not (0/1)\n",
        "train_df.loc[NotImplemented] = NotImplemented # Replace with the correct threshold value and label value\n",
        "\n",
        "\n",
        "# MinMax normalization (from 0 to 1)\n",
        "# TODO: Create a normalized version of the 'cycle' column (e.g., 'cycle_norm') using the original 'cycle' values\n",
        "train_df['cycle_norm'] = NotImplemented  # Replace with the correct normalization code\n",
        "# TODO: Select the columns to be normalized (all columns except 'id', 'cycle', 'RUL', 'label1', and 'label2')\n",
        "cols_normalize = NotImplemented  # Replace with the correct column selection code\n",
        "# TODO: Initialize a MinMaxScaler object to scale values between 0 and 1\n",
        "min_max_scaler = NotImplemented  # Replace with the correct scaler initialization code\n",
        "# TODO: Apply MinMaxScaler to the selected columns and create a new normalized DataFrame\n",
        "norm_train_df = NotImplemented  # Replace with the correct normalization code\n",
        "# TODO: Join the normalized DataFrame with the original DataFrame (excluding normalized columns)\n",
        "join_df = NotImplemented  # Replace with the correct join code\n",
        "# TODO: Reorder the columns in the joined DataFrame to match the original order\n",
        "train_df = NotImplemented  # Replace with the correct reindexing code\n",
        "\n",
        "######\n",
        "# TEST\n",
        "######\n",
        "# MinMax normalization (from 0 to 1)\n",
        "# TODO: Similar to the MinMax normalization done for Train, complete the code below.\n",
        "test_df['cycle_norm'] = NotImplemented\n",
        "norm_test_df = NotImplemented\n",
        "test_join_df = NotImplemented\n",
        "test_df = NotImplemented\n",
        "test_df = NotImplemented\n",
        "\n",
        "# We use the ground truth dataset to generate labels for the test data.\n",
        "# generate column max for test data\n",
        "# TODO: Calculate the maximum cycle value for each engine (id) in the test data and store it in a new DataFrame (rul)\n",
        "rul = NotImplemented\n",
        "# TODO: Rename the columns in the rul DataFrame\n",
        "rul.columns = NotImplemented\n",
        "# TODO: Merge the rul DataFrame with the original test_df based on the 'id' column\n",
        "truth_df.columns = ['more']\n",
        "truth_df['id'] = truth_df.index + 1\n",
        "truth_df['max'] = rul['max'] + truth_df['more']\n",
        "# TODO: Remove the temporary column used to calculate RUL\n",
        "truth_df.drop(NotImplemented, axis=1, inplace=True)\n",
        "\n",
        "# TODO: Merge the adjusted truth_df with the test_df to generate RUL values for test data\n",
        "test_df = NotImplemented\n",
        "# TODO: Calculate the Remaining Useful Life (RUL) by subtracting the current cycle from the maximum cycle\n",
        "test_df['RUL'] = NotImplemented\n",
        "# TODO: Remove the temporary column used to calculate RUL\n",
        "test_df.drop(NotImplemented, axis=1, inplace=True)\n",
        "\n",
        "# Generate binary label columns (label1 and label2) based on RUL values and thresholds w0 and w1\n",
        "# TODO: Similar to what you did in the train dataframe\n",
        "test_df['label1'] = NotImplemented\n",
        "test_df['label2'] = NotImplemented\n",
        "test_df.loc[NotImplemented] = NotImplemented"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57FSFDb4-r3d"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NToa3NezS-OX"
      },
      "outputs": [],
      "source": [
        "# TODO: Define window size and sequence length\n",
        "sequence_length = NotImplemented  # Replace with the desired sequence length\n",
        "\n",
        "# Function to reshape features into (samples, time steps, features)\n",
        "def generate_sequences(id_df, sequence_length, feature_columns):\n",
        "    \"\"\"Generate sequences from a dataframe for a given id.\n",
        "    Sequences that are under the sequence length will be considered.\n",
        "    We can also pad the sequences in order to use shorter ones.\"\"\"\n",
        "    data_matrix = id_df[feature_columns].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "\n",
        "    for start, end in zip(range(0, num_elements - sequence_length), range(sequence_length, num_elements)):\n",
        "        yield NotImplemented  # TODO: Replace with the correct code to yield sequences of feature values\n",
        "\n",
        "# TODO: Select feature columns for sequence generation (e.g., sensor readings, settings)\n",
        "sensor_columns = NotImplemented  # TODO: Replace with the correct list of sensor column names\n",
        "sequence_columns = NotImplemented  # TODO: Replace with the correct list of sequence column names (including settings and sensors)\n",
        "\n",
        "# TODO: Generate sequences for all engine ids in the training data\n",
        "sequence_generator = NotImplemented  # TODO: Replace with the correct code to generate sequences\n",
        "\n",
        "# TODO: Convert generated sequences to a numpy array for LSTM input\n",
        "sequence_array = NotImplemented  # TODO: Replace with the correct code to convert sequences to numpy array\n",
        "\n",
        "# TODO: Function to generate labels\n",
        "def generate_labels(id_df, sequence_length, label_column):\n",
        "    \"\"\"Generate labels for a given id.\"\"\"\n",
        "    data_matrix = id_df[label_column].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    return NotImplemented  # TODO: Replace with the correct code to generate labels\n",
        "\n",
        "# TODO: Generate labels for all engine ids in the training data\n",
        "label_generator = NotImplemented  # TODO: Replace with the correct code to generate labels for all engine ids\n",
        "label_array = NotImplemented  # TODO: Replace with the correct code to convert labels to a numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_VqVFhdq0tR"
      },
      "outputs": [],
      "source": [
        "# Define the number of features and output units\n",
        "nb_features = sequence_array.shape[2]\n",
        "nb_out = label_array.shape[1]\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# TODO: Add LSTM layers and Dropout layers to the model\n",
        "# Note: Limit the total number of model parameters to 10,000\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "# Add a Dense output layer with sigmoid activation\n",
        "model.add(Dense(units=nb_out, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with binary crossentropy loss and Adam optimizer\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# TODO: Print the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JUi08eUonh7"
      },
      "outputs": [],
      "source": [
        "# TODO: Fit the network to the training data\n",
        "history = model.fit(\n",
        "    sequence_array,\n",
        "    label_array,\n",
        "    epochs=NotImplemented,  # TODO: Replace with the desired number of training epochs\n",
        "    batch_size=NotImplemented,  # TODO: Replace with the desired batch size\n",
        "    validation_split=NotImplemented,  # TODO: Replace with the desired validation split proportion\n",
        "    verbose=NotImplemented,  # TODO: Replace with the desired verbosity level\n",
        "    callbacks = [\n",
        "        # TODO: Early stopping callback to stop training when validation loss stops improving\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            min_delta=NotImplemented,  # TODO: Replace with the minimum change in validation loss to qualify as improvement\n",
        "            patience=NotImplemented,  # TODO: Replace with the number of epochs to wait before stopping training\n",
        "            verbose=NotImplemented,  # TODO: Replace with the desired verbosity level\n",
        "            mode='min'\n",
        "        ),\n",
        "        # TODO: Model checkpoint callback to save the best model based on validation loss\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "            NotImplemented,  # TODO: Replace with the file path to save the best model\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            mode='min',\n",
        "            verbose=NotImplemented  # TODO: Replace with the desired verbosity level\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWyZJ2mP-1pB"
      },
      "source": [
        "## Model Evaluation on Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpVYSzXkmk5l"
      },
      "outputs": [],
      "source": [
        "# TODO: summarize history for Accuracy\n",
        "# TODO: Plot the training & validation accuracy over epochs and display the plot\n",
        "# TODO: Save the plot to a file\n",
        "\n",
        "\n",
        "# TODO: summarize history for Loss\n",
        "# TODO: Plot the training & validation loss over epochs and display the plot\n",
        "# TODO: Save the plot to a file\n",
        "\n",
        "# TODO: Use the evaluate method to calculate the accuracy of the model on the training data\n",
        "scores = NotImplemented  # TODO: Replace with the correct code to evaluate the model on the training data\n",
        "\n",
        "# Print the accuracy of the model on the training data\n",
        "\n",
        "# make predictions and compute confusion matrix\n",
        "# TODO: Use the predict method to make predictions on the training data\n",
        "# TODO: Convert the predicted probabilities to class labels (e.g., using a threshold of 0.5)\n",
        "y_pred = NotImplemented # TODO: Use predict and convert probabilities to class labels\n",
        "y_true = label_array\n",
        "\n",
        "# TODO: Create a Pandas DataFrame from the predicted labels and save it to a CSV file\n",
        "test_set = NotImplemented  # TODO: Replace with the correct code to create a DataFrame from the predicted labels\n",
        "\n",
        "print('Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
        "# TODO: Compute the confusion matrix using confusion_matrix from sklearn.metrics\n",
        "cm = NotImplemented  # TODO: Replace with the correct code to compute the confusion matrix\n",
        "print(cm)\n",
        "\n",
        "# TODO: Calculate the precision using precision_score and recall using recall_score from sklearn.metrics\n",
        "precision = NotImplemented  # TODO: Replace with the correct code to calculate precision\n",
        "recall = NotImplemented  # TODO: Replace with the correct code to calculate recall\n",
        "print( 'precision = ', precision, '\\n', 'recall = ', recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxvEuR4S-6VI"
      },
      "source": [
        "## Model Evaluation on Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yT96j4rkL0K"
      },
      "outputs": [],
      "source": [
        "# TODO: Pick the last sequence for each id in the test data\n",
        "seq_array_test_last = NotImplemented  # Replace with code to select last sequence for each id\n",
        "\n",
        "# TODO: Convert to numpy array and ensure float32 data type\n",
        "seq_array_test_last = NotImplemented\n",
        "\n",
        "# TODO: Pick the labels for the selected sequences\n",
        "y_mask = NotImplemented  # TODO: Replace with code to select labels for sequences with length >= sequence_length\n",
        "label_array_test_last = NotImplemented  # TODO: Replace with code to select labels for the selected sequences\n",
        "\n",
        "# Reshape and ensure float32 data type\n",
        "label_array_test_last = label_array_test_last.reshape(label_array_test_last.shape[0],1).astype(np.float32)\n",
        "\n",
        "# TODO: Load the saved model if it exists\n",
        "if os.path.isfile(model_path):\n",
        "    estimator = NotImplemented  # TODO: Replace with code to load the saved model\n",
        "\n",
        "# TODO: Evaluate the model on the test data\n",
        "scores_test = NotImplemented\n",
        "print('Accuracy: {}'.format(scores_test[1]))\n",
        "\n",
        "# TODO: Make predictions and compute confusion matrix\n",
        "y_pred_test = NotImplemented  # TODO: Replace with code to make predictions and convert to class labels\n",
        "y_true_test = label_array_test_last\n",
        "\n",
        "# TODO: Create pandas dataframe of y_pred_test and save predictions to CSV file\n",
        "test_set = NotImplemented\n",
        "\n",
        "# TODO: Compute confusion matrix\n",
        "print('Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
        "cm = NotImplemented  # TODO: Replace with code to compute confusion matrix\n",
        "print(cm)\n",
        "\n",
        "# TODO: Compute precision, recall, and F1-score\n",
        "precision_test = NotImplemented  # TODO: Replace with code to compute precision\n",
        "recall_test = NotImplemented  # TODO: Replace with code to compute recall\n",
        "f1_test = NotImplemented  # TODO: Replace with code to compute F1-score\n",
        "print('Precision: ', precision_test, '\\n', 'Recall: ', recall_test, '\\n', 'F1-score:', f1_test)\n",
        "\n",
        "# TODO: Plot predicted and actual data for visual verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy1uAcAJqFf6"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame([[scores_test[1],precision_test,recall_test,f1_test],\n",
        "                          [0.94, 0.952381, 0.8, 0.869565]],\n",
        "                         columns = ['Accuracy', 'Precision', 'Recall', 'F1-score'],\n",
        "                         index = ['LSTM',\n",
        "                                 'Template Best Model'])\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwPU_ybuqSl7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
